{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436d1912-dca0-420b-83fa-651f7ffc0d6f",
   "metadata": {},
   "source": [
    "<center>Jaime Francisco Barbosa Hernández   ID:615152<center>\n",
    "\n",
    "<center>SC3314 – Inteligencia Artificial Universidad de Monterrey Dr. Antonio Martínez Torteya</center>\n",
    "\n",
    "## A3.1 SVM y Multiple Testing\n",
    "\n",
    "En esta actividad trabajarás con la base de datos de la que se habló en clase, que consiste de 83 muestras y 2308 variables de entrada, que consisten en la expresión génica estandarizada\n",
    "de distintos genes. La variable de salida cuenta con valores numéricos del 1 al 4 que corresponden a distintos tipos de cáncer.\n",
    "\n",
    "Desarrolla los siguientes puntos en una Jupyter Notebook, tratando, dentro de lo posible, que cada punto se trabaje en una celda distinta. Los comentarios en el código siempre son\n",
    "bienvenidos, de preferencia, aprovecha el markdown para generar cuadros de descripción que ayuden al lector a comprender el trabajo realizado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a401c177-ad10-4eac-ae53-923adb3aa42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f25e1-5679-4c91-b515-71712579949e",
   "metadata": {},
   "source": [
    "1. Importa los datos a tu ambiente de trabajo y revisa que no haya huecos. Calcula la diferencia de promedios entre las clases 2 y 4 para todos los genes, e imprime los 10 genes con la mayor diferencia de medias. Indica qué crees que esta diferencia podría implicar en términos de un estudio de inferencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4e9eaca-a12b-4893-9efe-a29ec715b5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension es del Data Frame:  (83, 2309)\n",
      "\n",
      "Huecos:  0\n",
      "\n",
      "         X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0  0.773344 -2.438405 -0.482562 -2.721135 -1.217058  0.827809  1.342604   \n",
      "1 -0.078178 -2.415754  0.412772 -2.825146 -0.626236  0.054488  1.429498   \n",
      "2 -0.084469 -1.649739 -0.241308 -2.875286 -0.889405 -0.027474  1.159300   \n",
      "3  0.965614 -2.380547  0.625297 -1.741256 -0.845366  0.949687  1.093801   \n",
      "4  0.075664 -1.728785  0.852626  0.272695 -1.841370  0.327936  1.251219   \n",
      "\n",
      "         X8        X9       X10  ...     X2300     X2301     X2302     X2303  \\\n",
      "0  0.057042  0.133569  0.565427  ... -0.027474 -1.660205  0.588231 -0.463624   \n",
      "1 -0.120249  0.456792  0.159053  ... -0.246284 -0.836325 -0.571284  0.034788   \n",
      "2  0.015676  0.191942  0.496585  ...  0.024985 -1.059872 -0.403767 -0.678653   \n",
      "3  0.819736 -0.284620  0.994732  ...  0.357115 -1.893128  0.255107  0.163309   \n",
      "4  0.771450  0.030917  0.278313  ...  0.061753 -2.273998 -0.039365  0.368801   \n",
      "\n",
      "      X2304     X2305     X2306     X2307     X2308  y  \n",
      "0 -3.952845 -5.496768 -1.414282 -0.647600 -1.763172  2  \n",
      "1 -2.478130 -3.661264 -1.093923 -1.209320 -0.824395  2  \n",
      "2 -2.939352 -2.736450 -1.965399 -0.805868 -1.139434  2  \n",
      "3 -1.021929 -2.077843 -1.127629  0.331531 -2.179483  2  \n",
      "4 -2.566551 -1.675044 -1.082050 -0.965218 -1.836966  2  \n",
      "\n",
      "[5 rows x 2309 columns]\n",
      "\n",
      "X187     3.323151\n",
      "X509     2.906537\n",
      "X2046    2.424515\n",
      "X2050    2.401783\n",
      "X129     2.165185\n",
      "X1645    2.065460\n",
      "X1319    2.045941\n",
      "X1955    2.037340\n",
      "X1003    2.011337\n",
      "X246     1.837830\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"A3.1 Khan.csv\")\n",
    "\n",
    "print(\"Dimension es del Data Frame: \",df.shape)\n",
    "print()\n",
    "print(\"Huecos: \",df.isnull().sum().sum())\n",
    "print()\n",
    "print(df.head())\n",
    "print()\n",
    "\n",
    "# Filtrar por clases 2 y 4\n",
    "class_2 = df[df['y'] == 2].drop('y', axis=1)\n",
    "class_4 = df[df['y'] == 4].drop('y', axis=1)\n",
    "\n",
    "# Diferencia de medias\n",
    "diff_means = class_2.mean() - class_4.mean()\n",
    "\n",
    "# Top 10 genes con mayor diferencia absoluta\n",
    "top10 = diff_means.abs().sort_values(ascending=False).head(10)\n",
    "print(top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffeb087-f75a-4163-a696-565e9977597b",
   "metadata": {},
   "source": [
    "Una diferencia de medias entre clases 2 y 4 podría indicar que esos genes están expresados de forma distinta en los dos tipos de tejido o condición estudiada. En un contexto de inferencia, esto sugiere que esos genes podrían ser buenos candidatos para pruebas de hipótesis entre ambas clases, aunque aún se requeriría aplicar pruebas estadísticas más formales, como t-test o corrección por multiple testing para confirmar su verdadera significancia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b921899-2127-452e-b9fe-ce1667ceac6f",
   "metadata": {},
   "source": [
    "2. Calcula el estadístico t y el p-value para comparar las medias de todos los genes entre la clase 2 y la clase 4 de la base de datos. Usa la metodología de Bonferroni, de Holm, y de Benjamini-Hochberg para corregir por múltiples pruebas e indica, para cada una, qué genes tienen una expresión significativamente distinta entre las clases (maneja un control de 0.05). Te recomiendo usar la función multipletests de statsmodels.stats.multitest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0cf53a6-6c42-48a5-8dcc-34315b9f64d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significativos (Bonferroni): 72\n",
      "Significativos (Holm): 72\n",
      "Significativos (Benjamini-Hochberg): 296\n",
      "\n",
      "Bonferroni genes:\n",
      " ['X2' 'X36' 'X67' 'X129' 'X174' 'X187' 'X188' 'X229' 'X246' 'X251' 'X338'\n",
      " 'X348' 'X368' 'X372' 'X373' 'X380' 'X430' 'X433' 'X509' 'X545' 'X554'\n",
      " 'X558' 'X566' 'X603' 'X655' 'X714' 'X762' 'X910' 'X951' 'X971' 'X1003'\n",
      " 'X1021' 'X1023' 'X1055' 'X1070' 'X1093' 'X1105' 'X1110' 'X1112' 'X1132'\n",
      " 'X1194' 'X1196' 'X1207' 'X1217' 'X1298' 'X1319' 'X1327' 'X1330' 'X1372'\n",
      " 'X1389' 'X1416' 'X1610' 'X1626' 'X1634' 'X1645' 'X1706' 'X1708' 'X1723'\n",
      " 'X1738' 'X1799' 'X1888' 'X1896' 'X1911' 'X1924' 'X1954' 'X1955' 'X1980'\n",
      " 'X2046' 'X2050' 'X2115' 'X2146' 'X2247']\n",
      "\n",
      "Holm genes:\n",
      " ['X2' 'X36' 'X67' 'X129' 'X174' 'X187' 'X188' 'X229' 'X246' 'X251' 'X338'\n",
      " 'X348' 'X368' 'X372' 'X373' 'X380' 'X430' 'X433' 'X509' 'X545' 'X554'\n",
      " 'X558' 'X566' 'X603' 'X655' 'X714' 'X762' 'X910' 'X951' 'X971' 'X1003'\n",
      " 'X1021' 'X1023' 'X1055' 'X1070' 'X1093' 'X1105' 'X1110' 'X1112' 'X1132'\n",
      " 'X1194' 'X1196' 'X1207' 'X1217' 'X1298' 'X1319' 'X1327' 'X1330' 'X1372'\n",
      " 'X1389' 'X1416' 'X1610' 'X1626' 'X1634' 'X1645' 'X1706' 'X1708' 'X1723'\n",
      " 'X1738' 'X1799' 'X1888' 'X1896' 'X1911' 'X1924' 'X1954' 'X1955' 'X1980'\n",
      " 'X2046' 'X2050' 'X2115' 'X2146' 'X2247']\n",
      "\n",
      "BH genes:\n",
      " ['X2' 'X3' 'X29' 'X36' 'X52' 'X67' 'X80' 'X89' 'X119' 'X129' 'X131' 'X139'\n",
      " 'X141' 'X146' 'X151' 'X153' 'X165' 'X166' 'X169' 'X174' 'X187' 'X188'\n",
      " 'X191' 'X214' 'X217' 'X229' 'X230' 'X244' 'X246' 'X251' 'X256' 'X258'\n",
      " 'X315' 'X323' 'X335' 'X336' 'X338' 'X340' 'X348' 'X365' 'X368' 'X372'\n",
      " 'X373' 'X378' 'X380' 'X384' 'X388' 'X390' 'X407' 'X409' 'X419' 'X426'\n",
      " 'X430' 'X433' 'X437' 'X443' 'X465' 'X469' 'X481' 'X482' 'X483' 'X500'\n",
      " 'X501' 'X503' 'X509' 'X518' 'X533' 'X534' 'X542' 'X545' 'X554' 'X558'\n",
      " 'X566' 'X598' 'X603' 'X604' 'X607' 'X636' 'X642' 'X650' 'X655' 'X696'\n",
      " 'X702' 'X714' 'X715' 'X733' 'X744' 'X746' 'X747' 'X753' 'X758' 'X760'\n",
      " 'X761' 'X762' 'X774' 'X779' 'X789' 'X795' 'X803' 'X808' 'X820' 'X828'\n",
      " 'X832' 'X851' 'X857' 'X867' 'X883' 'X891' 'X910' 'X941' 'X951' 'X964'\n",
      " 'X971' 'X973' 'X979' 'X982' 'X1003' 'X1012' 'X1020' 'X1021' 'X1022'\n",
      " 'X1023' 'X1030' 'X1037' 'X1039' 'X1046' 'X1055' 'X1063' 'X1070' 'X1074'\n",
      " 'X1089' 'X1090' 'X1093' 'X1100' 'X1105' 'X1110' 'X1112' 'X1113' 'X1125'\n",
      " 'X1132' 'X1151' 'X1155' 'X1158' 'X1160' 'X1164' 'X1187' 'X1194' 'X1196'\n",
      " 'X1201' 'X1203' 'X1204' 'X1206' 'X1207' 'X1217' 'X1220' 'X1225' 'X1227'\n",
      " 'X1228' 'X1238' 'X1252' 'X1254' 'X1258' 'X1263' 'X1283' 'X1286' 'X1292'\n",
      " 'X1298' 'X1301' 'X1319' 'X1325' 'X1327' 'X1330' 'X1331' 'X1345' 'X1353'\n",
      " 'X1372' 'X1389' 'X1416' 'X1464' 'X1489' 'X1493' 'X1496' 'X1497' 'X1498'\n",
      " 'X1517' 'X1518' 'X1525' 'X1536' 'X1574' 'X1597' 'X1606' 'X1610' 'X1613'\n",
      " 'X1626' 'X1634' 'X1643' 'X1644' 'X1645' 'X1646' 'X1655' 'X1670' 'X1671'\n",
      " 'X1673' 'X1677' 'X1691' 'X1697' 'X1706' 'X1708' 'X1714' 'X1723' 'X1727'\n",
      " 'X1729' 'X1734' 'X1738' 'X1771' 'X1772' 'X1775' 'X1778' 'X1799' 'X1821'\n",
      " 'X1822' 'X1831' 'X1850' 'X1853' 'X1854' 'X1855' 'X1857' 'X1867' 'X1870'\n",
      " 'X1878' 'X1882' 'X1888' 'X1896' 'X1901' 'X1906' 'X1909' 'X1910' 'X1911'\n",
      " 'X1914' 'X1917' 'X1920' 'X1924' 'X1929' 'X1931' 'X1937' 'X1942' 'X1945'\n",
      " 'X1954' 'X1955' 'X1967' 'X1979' 'X1980' 'X1991' 'X1994' 'X1995' 'X2000'\n",
      " 'X2020' 'X2039' 'X2046' 'X2047' 'X2049' 'X2050' 'X2060' 'X2080' 'X2081'\n",
      " 'X2083' 'X2086' 'X2088' 'X2093' 'X2096' 'X2099' 'X2105' 'X2114' 'X2115'\n",
      " 'X2117' 'X2120' 'X2146' 'X2148' 'X2149' 'X2159' 'X2172' 'X2181' 'X2199'\n",
      " 'X2227' 'X2230' 'X2235' 'X2247' 'X2248' 'X2253' 'X2262' 'X2275' 'X2278'\n",
      " 'X2295' 'X2300' 'X2301' 'X2303']\n"
     ]
    }
   ],
   "source": [
    "# 3. Calcular t-test para cada gen\n",
    "t_values = []\n",
    "p_values = []\n",
    "\n",
    "for gene in class_2.columns:\n",
    "    t_stat, p_val = ttest_ind(class_2[gene], class_4[gene], equal_var=False)\n",
    "    t_values.append(t_stat)\n",
    "    p_values.append(p_val)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'gene': class_2.columns,\n",
    "    't_stat': t_values,\n",
    "    'p_value': p_values\n",
    "})\n",
    "\n",
    "# 4. Correcciones por pruebas múltiples\n",
    "alpha = 0.05\n",
    "\n",
    "# Bonferroni\n",
    "results['bonf_reject'], results['bonf_p'], _, _ = multipletests(results['p_value'], alpha=alpha, method='bonferroni')\n",
    "\n",
    "# Holm\n",
    "results['holm_reject'], results['holm_p'], _, _ = multipletests(results['p_value'], alpha=alpha, method='holm')\n",
    "\n",
    "# Benjamini-Hochberg (FDR)\n",
    "results['bh_reject'], results['bh_p'], _, _ = multipletests(results['p_value'], alpha=alpha, method='fdr_bh')\n",
    "\n",
    "# 5. Genes significativos en cada método\n",
    "sig_bonf = results[results['bonf_reject']]\n",
    "sig_holm = results[results['holm_reject']]\n",
    "sig_bh   = results[results['bh_reject']]\n",
    "\n",
    "print(\"Significativos (Bonferroni):\", sig_bonf.shape[0])\n",
    "print(\"Significativos (Holm):\", sig_holm.shape[0])\n",
    "print(\"Significativos (Benjamini-Hochberg):\", sig_bh.shape[0])\n",
    "\n",
    "# Opcional: mostrar nombres de genes significativos\n",
    "print(\"\\nBonferroni genes:\\n\", sig_bonf['gene'].values)\n",
    "print(\"\\nHolm genes:\\n\", sig_holm['gene'].values)\n",
    "print(\"\\nBH genes:\\n\", sig_bh['gene'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d3861-abe7-4179-b64b-3183acabb45a",
   "metadata": {},
   "source": [
    "En este inciso podemos ver que primero se realiza la prueba t para comparar las medias de todos los genes entre la clase 2 y la clase 4 de la base de datos y encontrar si tienen una diferecia estadísticamente significativa. Por último, se utilizan métodos de validación multiple (Bonferroni, Holm y Benjamini-Hochberg \"FDR\"), imprimiendo los genes más significativos considerados por cada método."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feefca46-de26-4466-a28f-cc75c3302190",
   "metadata": {},
   "source": [
    "3. Realiza un experimento similar, pero ahora comparando las medias de las 4 clases de la base de datos. Para lograrlo, en vez de trabajar con el estadístico t, te recomiendo realizar pruebas de análisis de varianza (ANOVA). Dicha prueba la puedes realizar con la función f_oneway de scipy.stats, pero revisa bien cómo se deben ingresar los datos a dicha función, necesitarás primero estratificarlos por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f75c6644-2091-4f88-a8ad-051271fcf0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 3 1]\n",
      "Genes con diferencia significativa entre las 4 clases (ANOVA): 1303\n",
      "Genes significativos (Bonferroni): 404\n",
      "Genes significativos (Holm): 412\n",
      "Genes significativos (Benjamini-Hochberg): 1162\n",
      "\n",
      "   gene     F_stat       p_value\n",
      "0    X1  59.118264  3.839240e-20\n",
      "1    X2  31.279175  1.977997e-13\n",
      "2    X3  13.099869  5.004749e-07\n",
      "8    X9   8.156223  8.500660e-05\n",
      "11  X12   3.313432  2.418413e-02\n",
      "16  X17  12.543986  8.650499e-07\n",
      "20  X21   3.958019  1.103851e-02\n",
      "21  X22   3.792741  1.348825e-02\n",
      "22  X23   2.739617  4.882749e-02\n",
      "25  X26   2.761909  4.751099e-02\n",
      "\n",
      "Bonferroni (primeros 10):\n",
      "    gene     F_stat       p_value  bonf_reject        bonf_p  holm_reject  \\\n",
      "0    X1  59.118264  3.839240e-20         True  8.860966e-17         True   \n",
      "1    X2  31.279175  1.977997e-13         True  4.565218e-10         True   \n",
      "2    X3  13.099869  5.004749e-07         True  1.155096e-03         True   \n",
      "16  X17  12.543986  8.650499e-07         True  1.996535e-03         True   \n",
      "28  X29  17.558086  7.937953e-09         True  1.832080e-05         True   \n",
      "32  X33  13.082331  5.091346e-07         True  1.175083e-03         True   \n",
      "35  X36  11.859150  1.714709e-06         True  3.957547e-03         True   \n",
      "49  X50  12.331116  1.068771e-06         True  2.466724e-03         True   \n",
      "51  X52  11.881543  1.676474e-06         True  3.869302e-03         True   \n",
      "53  X54  10.057340  1.096182e-05         True  2.529987e-02         True   \n",
      "\n",
      "          holm_p  bh_reject          bh_p  \n",
      "0   8.837930e-17       True  1.265852e-17  \n",
      "1   4.456428e-10       True  8.152174e-12  \n",
      "2   1.031479e-03       True  4.657645e-06  \n",
      "16  1.767297e-03       True  7.505772e-06  \n",
      "28  1.706660e-05       True  1.152251e-07  \n",
      "32  1.048817e-03       True  4.719207e-06  \n",
      "35  3.451708e-03       True  1.337009e-05  \n",
      "49  2.179225e-03       True  9.136015e-06  \n",
      "51  3.376419e-03       True  1.311628e-05  \n",
      "53  2.129881e-02       True  6.912533e-05  \n",
      "\n",
      "Holm (primeros 10):\n",
      "    gene     F_stat       p_value  bonf_reject        bonf_p  holm_reject  \\\n",
      "0    X1  59.118264  3.839240e-20         True  8.860966e-17         True   \n",
      "1    X2  31.279175  1.977997e-13         True  4.565218e-10         True   \n",
      "2    X3  13.099869  5.004749e-07         True  1.155096e-03         True   \n",
      "16  X17  12.543986  8.650499e-07         True  1.996535e-03         True   \n",
      "28  X29  17.558086  7.937953e-09         True  1.832080e-05         True   \n",
      "32  X33  13.082331  5.091346e-07         True  1.175083e-03         True   \n",
      "35  X36  11.859150  1.714709e-06         True  3.957547e-03         True   \n",
      "49  X50  12.331116  1.068771e-06         True  2.466724e-03         True   \n",
      "51  X52  11.881543  1.676474e-06         True  3.869302e-03         True   \n",
      "53  X54  10.057340  1.096182e-05         True  2.529987e-02         True   \n",
      "\n",
      "          holm_p  bh_reject          bh_p  \n",
      "0   8.837930e-17       True  1.265852e-17  \n",
      "1   4.456428e-10       True  8.152174e-12  \n",
      "2   1.031479e-03       True  4.657645e-06  \n",
      "16  1.767297e-03       True  7.505772e-06  \n",
      "28  1.706660e-05       True  1.152251e-07  \n",
      "32  1.048817e-03       True  4.719207e-06  \n",
      "35  3.451708e-03       True  1.337009e-05  \n",
      "49  2.179225e-03       True  9.136015e-06  \n",
      "51  3.376419e-03       True  1.311628e-05  \n",
      "53  2.129881e-02       True  6.912533e-05  \n",
      "\n",
      "Benjamini–Hochberg (primeros 10):\n",
      "    gene     F_stat       p_value  bonf_reject        bonf_p  holm_reject  \\\n",
      "0    X1  59.118264  3.839240e-20         True  8.860966e-17         True   \n",
      "1    X2  31.279175  1.977997e-13         True  4.565218e-10         True   \n",
      "2    X3  13.099869  5.004749e-07         True  1.155096e-03         True   \n",
      "8    X9   8.156223  8.500660e-05        False  1.961952e-01        False   \n",
      "11  X12   3.313432  2.418413e-02        False  1.000000e+00        False   \n",
      "16  X17  12.543986  8.650499e-07         True  1.996535e-03         True   \n",
      "20  X21   3.958019  1.103851e-02        False  1.000000e+00        False   \n",
      "21  X22   3.792741  1.348825e-02        False  1.000000e+00        False   \n",
      "26  X27   7.214402  2.431093e-04        False  5.610962e-01        False   \n",
      "28  X29  17.558086  7.937953e-09         True  1.832080e-05         True   \n",
      "\n",
      "          holm_p  bh_reject          bh_p  \n",
      "0   8.837930e-17       True  1.265852e-17  \n",
      "1   4.456428e-10       True  8.152174e-12  \n",
      "2   1.031479e-03       True  4.657645e-06  \n",
      "8   1.549670e-01       True  4.036939e-04  \n",
      "11  1.000000e+00       True  4.820118e-02  \n",
      "16  1.767297e-03       True  7.505772e-06  \n",
      "20  1.000000e+00       True  2.510037e-02  \n",
      "21  1.000000e+00       True  2.981886e-02  \n",
      "26  4.237395e-01       True  9.913361e-04  \n",
      "28  1.706660e-05       True  1.152251e-07  \n"
     ]
    }
   ],
   "source": [
    "# Verifica qué clases existen\n",
    "print(df['y'].unique())\n",
    "\n",
    "# 2. Separar los datos por clase\n",
    "groups = [df[df['y'] == c].drop('y', axis=1) for c in sorted(df['y'].unique())]\n",
    "\n",
    "# 3. ANOVA para cada gen\n",
    "f_stats = []\n",
    "p_values = []\n",
    "\n",
    "for gene in groups[0].columns:\n",
    "    data = [g[gene] for g in groups]   # una lista de vectores (uno por clase)\n",
    "    f_stat, p_val = f_oneway(*data)\n",
    "    f_stats.append(f_stat)\n",
    "    p_values.append(p_val)\n",
    "\n",
    "results_anova = pd.DataFrame({\n",
    "    'gene': groups[0].columns,\n",
    "    'F_stat': f_stats,\n",
    "    'p_value': p_values\n",
    "})\n",
    "\n",
    "# 4. Genes con diferencia significativa (α=0.05)\n",
    "significant_genes = results_anova[results_anova['p_value'] < 0.05]\n",
    "\n",
    "print(\"Genes con diferencia significativa entre las 4 clases (ANOVA):\", significant_genes.shape[0])\n",
    "\n",
    "# 4. Correcciones múltiples\n",
    "alpha = 0.05\n",
    "\n",
    "results_anova['bonf_reject'], results_anova['bonf_p'], _, _ = multipletests(results_anova['p_value'], alpha=alpha, method='bonferroni')\n",
    "results_anova['holm_reject'], results_anova['holm_p'], _, _ = multipletests(results_anova['p_value'], alpha=alpha, method='holm')\n",
    "results_anova['bh_reject'],   results_anova['bh_p'],   _, _ = multipletests(results_anova['p_value'], alpha=alpha, method='fdr_bh')\n",
    "\n",
    "# 5. Genes significativos según cada método\n",
    "sig_bonf = results_anova[results_anova['bonf_reject']]\n",
    "sig_holm = results_anova[results_anova['holm_reject']]\n",
    "sig_bh   = results_anova[results_anova['bh_reject']]\n",
    "\n",
    "print(\"Genes significativos (Bonferroni):\", sig_bonf.shape[0])\n",
    "print(\"Genes significativos (Holm):\", sig_holm.shape[0])\n",
    "print(\"Genes significativos (Benjamini-Hochberg):\", sig_bh.shape[0])\n",
    "print()\n",
    "\n",
    "print(significant_genes.head(10))\n",
    "\n",
    "print(\"\\nBonferroni (primeros 10):\\n\", sig_bonf.head(10))\n",
    "print(\"\\nHolm (primeros 10):\\n\", sig_holm.head(10))\n",
    "print(\"\\nBenjamini–Hochberg (primeros 10):\\n\", sig_bh.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b30e69-5d40-49ed-928a-200502af042e",
   "metadata": {},
   "source": [
    "Para este inciso, se realizó un proceso muy similar al anterior. Primeramente se hizo un análisis ANOVA para comparar las medias entre las 4 clases, y definir cuales tienen una diferencia significativa. Y a partir de lo obtenido en el ANOVA, se utilizan las metodologías de corrección anteriormente utilizadas. Por último se despliegan la cantidad de variables significativas según cada método, y se imprimen las primeras 10 variables para cada una."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17682619-7d7f-4c23-8ffe-4e56777b600a",
   "metadata": {},
   "source": [
    "4. Separa los datos en entrenamiento y prueba, construye y entrena un modelo de SVM con un kernel lineal, con un kernel polinomial de orden 3, y con un kernel radial (puedes usar los parámetros que gustes, no necesitas optimizar con validación cruzada). Para evitar que el tiempo de procesamiento sea exagerado, puedes seleccionar solamente algunas variables, partiendo de los resultados que obtuviste en los puntos anteriores. Esta no es una práctica adecuada, pues estamos cayendo en una situación de fuga de datos. Lo ideal sería que la selección de características se basara solamente en experimentos realizados con los datos de entrenamiento. Pero, en este caso, obviaremos este detalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d18c20f-09f2-4891-a473-72c0764e64ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_genes = np.random.choice(sig_bonf['gene'], size=40, replace=False)\n",
    "X = df[selected_genes]\n",
    "y = df['y']\n",
    "\n",
    "# 3. Separar en entrenamiento y prueba (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# 4. Escalamiento\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5. Modelos SVM\n",
    "\n",
    "# Lineal\n",
    "svm_linear = SVC(kernel='linear')\n",
    "svm_linear.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Polinomial grado 3\n",
    "svm_poly = SVC(kernel='poly', degree=3)\n",
    "svm_poly.fit(X_train_scaled, y_train)\n",
    "\n",
    "# RBF\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "svm_rbf.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b9785-b6b2-4bf8-a8a1-d64743479ec5",
   "metadata": {},
   "source": [
    "Para este inciso, como lo indica el problema, se omite el paso de selección de características, que si bien es lo correcto de realizar, por fines de capacidad computacional no se hará ese paso. En lugar de ello, se seleccionaron 40 características de manera \"al azar\" con la función *random.choice* de **numpy**. Después se separaron en train-test el DF con una razón de 70/30 respectivamente, y asegurandose se estratificar. Como paso intermedio, se utiliza *StandardScaler* pra estalar las características. Y por último se entrenan los 3 modelos con sus respectivos kernels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca8780-692f-475a-862b-8c2103afb687",
   "metadata": {},
   "source": [
    "5. Calcula, para los 3 modelos, las métricas que consideres importantes para comparar los desempeños. Indica qué opinas sobre los resultados, especificando si crees que uno de los kernels es mejor para esta tarea específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30009560-dcd8-4ef2-9559-b76b492870e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud SVM Lineal:  1.0\n",
      "Exactitud SVM Polinomial:  0.8\n",
      "Exactitud SVM RBF:  0.96\n",
      "\n",
      "Precisión SVM Lineal:  1.0\n",
      "Precisión SVM Polinomial:  0.8714285714285714\n",
      "Precisión SVM RBF:  0.9644444444444444\n",
      "\n",
      "Recall SVM Lineal:  1.0\n",
      "Recall SVM Polinomial:  0.8\n",
      "Recall SVM RBF:  0.96\n",
      "\n",
      "F1-Score SVM Lineal:  1.0\n",
      "F1-Score SVM Polinomial:  0.7906915113871636\n",
      "F1-Score SVM RBF:  0.9589542483660131\n"
     ]
    }
   ],
   "source": [
    "y_pred_linear = svm_linear.predict(X_test_scaled)\n",
    "y_pred_poly = svm_poly.predict(X_test_scaled)\n",
    "y_pred_rbf = svm_rbf.predict(X_test_scaled)\n",
    "acc_linear = accuracy_score(y_test, y_pred_linear)\n",
    "acc_poly = accuracy_score(y_test, y_pred_poly)\n",
    "acc_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "prec_linear = precision_score(y_test, y_pred_linear, average='weighted')\n",
    "prec_poly = precision_score(y_test, y_pred_poly, average='weighted')\n",
    "prec_rbf = precision_score(y_test, y_pred_rbf, average='weighted')\n",
    "rec_linear = recall_score(y_test, y_pred_linear, average='weighted')\n",
    "rec_poly = recall_score(y_test, y_pred_poly, average='weighted')\n",
    "rec_rbf = recall_score(y_test, y_pred_rbf, average='weighted')\n",
    "f1_linear = f1_score(y_test, y_pred_linear, average='weighted')\n",
    "f1_poly = f1_score(y_test, y_pred_poly, average='weighted')\n",
    "f1_rbf = f1_score(y_test, y_pred_rbf, average='weighted')\n",
    "print(\"Exactitud SVM Lineal: \", acc_linear)\n",
    "print(\"Exactitud SVM Polinomial: \", acc_poly)\n",
    "print(\"Exactitud SVM RBF: \", acc_rbf)\n",
    "print(\"\\nPrecisión SVM Lineal: \", prec_linear)\n",
    "print(\"Precisión SVM Polinomial: \", prec_poly)\n",
    "print(\"Precisión SVM RBF: \", prec_rbf)\n",
    "print(\"\\nRecall SVM Lineal: \", rec_linear)\n",
    "print(\"Recall SVM Polinomial: \", rec_poly)\n",
    "print(\"Recall SVM RBF: \", rec_rbf)\n",
    "print(\"\\nF1-Score SVM Lineal: \", f1_linear)\n",
    "print(\"F1-Score SVM Polinomial: \", f1_poly)\n",
    "print(\"F1-Score SVM RBF: \", f1_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195694d-a3b5-4a5d-a6eb-5641595b2073",
   "metadata": {},
   "source": [
    "Para los 3 modelos entrenados, se decidió obtener las métrica de *Exactitud*, *Precisión*, *Recall*, y *F1-Score*. Podemos observar que en general, el que peor desempeño tuvo fue el SVM con Kernel polinomial, pues obtuvo la puntuación más baja en todas las métricas. Los que en teoría mejor desempeño tuvieron fueron el SVM Lineal y el Radial. Si se tuviera que elegir un ganador según las métricas, viendo éstas el ganador sería el SVM Lineal, pues obtuvo un 100% en todo. Sin embargo recordemos que no se hizo un proceso de selección de características correcto, por lo que nuestros modelos muy probablemente tienen fugas de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6dc81-9993-4476-9c81-0f1f7a06b3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
